{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conducting Sentiment Analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Text of company's Management Discussion and Analysis (MD&A) section from Form 10-Q and 10-K. \n",
    "Output: Sentiment classified as either Positive or Negative along with the Sentiment confidence score in percentage\n",
    "\n",
    "Code is written in Python and uses following libraries:\n",
    "\n",
    "* PANDAS\n",
    "* NLTK\n",
    "* SKLEARN\n",
    "* RANDOM\n",
    "* STATISTICS\n",
    "\n",
    "Inaddition to above, it uses following files:\n",
    "\n",
    "    * lemur-stopwords.txt:File containing STOP words\n",
    "    * clasfuncdef.py:     Contains some of the custom functions and classes\n",
    "    * Negative terms.csv: Training file of Negative terms denoting Negative Sentiment\n",
    "    * Positive Terms.csv: Training file of Positive terms denoting Positive Sentiment\n",
    "    * TestNegative.txt:   Sample 10-K input file denoting Negative Sentiment. \n",
    "    * TestPositive.txt:   Sample 10-K input file denoting Positive Sentiment. \n",
    "    \n",
    "This Program shall evaluate Sentiment accuracy using following classifiers and then use the classifier with highest accuracy percentage to evaluate the 10-K input.\n",
    "\n",
    "    * Naive Bayes Classifier\n",
    "    * MultinomialNB Classifier\n",
    "    * BernoulliNB Classifier\n",
    "    * Logistic Regression Classifier\n",
    "    * SGD Classifier\n",
    "    * LinerSVC Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import clasfuncdef as cfd\n",
    "import nltk\n",
    "from statistics import mode\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing Positive Terms..\n",
      "Import Positive Terms complete !!\n",
      "\n",
      "Importing Negative Terms..\n",
      "Import Negative Terms complete !!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing Positive Terms..\")\n",
    "positive_terms = open(\"Positive Terms.csv\",\"r\").read()\n",
    "print(\"Import Positive Terms complete !!\")\n",
    "\n",
    "print(\"\")\n",
    "print(\"Importing Negative Terms..\")\n",
    "negative_terms = open(\"Negative Terms.csv\",\"r\").read()\n",
    "print(\"Import Negative Terms complete !!\")\n",
    "print(\"\")\n",
    "\n",
    "fname = 'TestPositive.txt'\n",
    "# fname = 'TestNegative.txt'\n",
    "\n",
    "# print(\"Importing Comments whose sentiment shall be analysed..\")\n",
    "# print(\"\")\n",
    "# print(\"Enter TestPositive.txt to analyse a Positive sample\")\n",
    "# print(\"Enter TestNegative.txt to analyse a Negative sample\")\n",
    "# print(\"\")\n",
    "\n",
    "# fname = input(\"Enter file name to analyze the sentiment: \")\n",
    "\n",
    "try:\n",
    "    src_comments = open(fname,\"r\").read()\n",
    "except Exception as e:\n",
    "    print('Unable to read the file !!')\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Vocabulary and collect sample Positive, Negative terms:\n",
    "\n",
    "It uses find_features function defined in the file clasfuncdef.py\n",
    "This function:\n",
    "* uses Lemmatizer instead of Stemming, since it is assumed that performance is not a concern for this project. \n",
    "* Uses the lemur-stopwords.txt file to remove the stop words.\n",
    "* Builds the featureset to be used in the classifer.\n",
    "\n",
    "Below is a snapshot of the function. \n",
    "def find_features(features_list, term):\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    str = lemmatizer.lemmatize(term)\n",
    "    words = word_tokenize(str)\n",
    "    stop_words = open(\"lemur-stopwords.txt\",\"r\").read()\n",
    "    filtered_sentence = [w for w in words if not w in stop_words]\n",
    "\n",
    "    features = {}\n",
    "    for w in features_list:\n",
    "        features[w] = (w in filtered_sentence)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building FeatureSet..\n",
      "FeatureSet determination complete !!\n"
     ]
    }
   ],
   "source": [
    "print('Building FeatureSet..')\n",
    "terms_collection = []\n",
    "vocabulary = []\n",
    "\n",
    "for r in positive_terms.split('\\n'):\n",
    "    terms_collection.append( (r, \"positive\") )\n",
    "    vocabulary.append(r.lower())\n",
    "\n",
    "for r in negative_terms.split('\\n'):\n",
    "    terms_collection.append( (r, \"negative\") )\n",
    "    vocabulary.append(r.lower())\n",
    "\n",
    "vocabulary = nltk.FreqDist(vocabulary)\n",
    "features_list = list(vocabulary.keys())\n",
    "featuresets = [(cfd.find_features(features_list, trm), category) for (trm, category) in terms_collection]\n",
    "random.shuffle(featuresets)\n",
    "\n",
    "print('FeatureSet determination complete !!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data into Training and Test. This shall be used in the classifer evalation. Classifers are trained using Train method and then tested for accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_training = featuresets[:50]\n",
    "set_testing =  featuresets[50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Naive Bayes Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes classifier accuracy %age: 69.64285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_classifier = nltk.NaiveBayesClassifier.train(set_training)\n",
    "print(\"Naive Bayes classifier accuracy %age:\", (nltk.classify.accuracy(NB_classifier, set_testing))*100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate MultinomialNB Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB classifier accuracy %age: 69.64285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MNB_classifier = SklearnClassifier(MultinomialNB())\n",
    "MNB_classifier.train(set_training)\n",
    "print(\"MultinomialNB classifier accuracy %age:\", (nltk.classify.accuracy(MNB_classifier, set_testing))*100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate BernoulliNB Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB classifier accuracy %age: 64.28571428571429\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BernoulliNB_classifier = SklearnClassifier(BernoulliNB())\n",
    "BernoulliNB_classifier.train(set_training)\n",
    "print(\"BernoulliNB classifier accuracy %age:\", (nltk.classify.accuracy(BernoulliNB_classifier, set_testing))*100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate Logistic Regression Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression classifier accuracy %age: 69.64285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LogisticRegression_classifier = SklearnClassifier(LogisticRegression())\n",
    "LogisticRegression_classifier.train(set_training)\n",
    "print(\"LogisticRegression classifier accuracy %age:\", (nltk.classify.accuracy(LogisticRegression_classifier, set_testing))*100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate SGD Classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD classifier accuracy %age: 69.64285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SGDClassifier_classifier = SklearnClassifier(SGDClassifier(max_iter=5, tol=None))\n",
    "SGDClassifier_classifier.train(set_training)\n",
    "print(\"SGD classifier accuracy %age:\", (nltk.classify.accuracy(SGDClassifier_classifier, set_testing))*100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate LinearSVC Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC classifier accuracy %age: 69.64285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LinearSVC_classifier = SklearnClassifier(LinearSVC())\n",
    "LinearSVC_classifier.train(set_training)\n",
    "print(\"LinearSVC classifier accuracy %age:\", (nltk.classify.accuracy(LinearSVC_classifier, set_testing))*100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the Classifiers and select the classifier with highest accuracy:\n",
    "selectclassifier is defined in the file clasfuncdef.py\n",
    "Below is a snapshot of the code:\n",
    "\n",
    "Mode functionality returns an error whenever two classifiers return the same accuracy percentage. Inorder to overcome this issue, I have defined the custom find_max_mode  function.\n",
    "\n",
    "def find_max_mode(list1):\n",
    "    list_table = statistics._counts(list1)\n",
    "    len_table = len(list_table)\n",
    "\n",
    "    if len_table == 1:\n",
    "        max_mode = statistics.mode(list1)\n",
    "    else:\n",
    "        new_list = []\n",
    "        for i in range(len_table):\n",
    "            new_list.append(list_table[i][0])\n",
    "        max_mode = max(new_list)\n",
    "    return max_mode\n",
    "\n",
    "class selectClassifier(ClassifierI):\n",
    "    def __init__(self, *classifiers):\n",
    "        self._classifiers = classifiers\n",
    "\n",
    "    def classify(self, features):\n",
    "        votes = []\n",
    "        for x in self._classifiers:\n",
    "            v = x.classify(features)\n",
    "            votes.append(v)\n",
    "        return find_max_mode(votes)\n",
    "\n",
    "    def confidence(self, features):\n",
    "        votes = []\n",
    "        for x in self._classifiers:\n",
    "            v = x.classify(features)\n",
    "            votes.append(v)\n",
    "\n",
    "        choice_votes = votes.count(find_max_mode(votes))\n",
    "        conf = choice_votes / len(votes)\n",
    "        return conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Classifier accuracy %age: 69.64285714285714\n",
      "\n"
     ]
    }
   ],
   "source": [
    "selected_classifier = cfd.selectClassifier(\n",
    "                                  LinearSVC_classifier,\n",
    "                                  MNB_classifier,\n",
    "                                  BernoulliNB_classifier,\n",
    "                                  LogisticRegression_classifier)\n",
    "\n",
    "print(\"Selected Classifier accuracy %age:\", (nltk.classify.accuracy(selected_classifier, set_testing))*100)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the Classifer is ready to evaluate the 10-K file. We will re-use the find features function defined above on the 10-K file to get the featureset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "features_src_comments = cfd.find_features(features_list,src_comments)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the Sentiment (Positive/Negative) and the confidence score (in percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment:  POSITIVE\n",
      "Sentiment Confidence:  100.0  %age\n"
     ]
    }
   ],
   "source": [
    "print('Sentiment: ', selected_classifier.classify(features_src_comments).upper())\n",
    "print('Sentiment Confidence: ', selected_classifier.confidence(features_src_comments)*100, ' %age')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
