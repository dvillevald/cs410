{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CS410 Text Information Systems Technology Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic: Sentiment Analysis using Python nltk for Financial Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Introduction\n",
    "\n",
    "In rencent years, the analysis of textual information for financial decision making has become increasingly popular.\n",
    "For instance, Li (2010) use it to predict future earnings, Kravet and Musli (2013) use textual analysis to predict stock prices and Humphreys et al. (2011) employ it for detecting corporate fraud. \n",
    "\n",
    "Academic research aside, the use of textual materials for conducting sentiment analysis is also important from an industry perspective. It is not difficult to see that effective sentiment analysis can be converted into potential alpha signals for quantitative fund managers.  \n",
    "\n",
    "A common method for discerning sentiment of a company is to run textual analysis on a company's Management Discussion and Analysis (MD&A) section of Form 10-Q and 10-K. Sentiment can be classified into positive, negative or neutral tones which can then be used to generate a signal for earnings or stock price prediction.\n",
    "\n",
    "In this note, we will review of the technologies used by quantitative fund managers and academics to determine stock / company sentiment via textual analysis. We also provide a basic tutorial in Python of how this works in practice.\n",
    "\n",
    "\n",
    "\n",
    "### Literature Review\n",
    "\n",
    "\n",
    "An overview of some academic papers on text analysis in the accounting and finance field.\n",
    "\n",
    "| Authors                      | Data                    | Method                                         |\n",
    "|------------------------------|-------------------------|------------------------------------------------|\n",
    "| Antweiler and Frank (2004)   | Yahoo! Finance Postings | single-label classifier                        |\n",
    "| Li (2008)                    | 10-K                    | content analysis: readability                  |\n",
    "| Tetlock et al. (2008)        | Financial News Articles | word categorization: positive / negative words |\n",
    "| Loughran and McDonald (2009) | 10-K                    | word categorization: positive / negative words |\n",
    "| Feldman et al. (2009)        | 10-K MD&A               | word categorization: positive / negative words |\n",
    "| Hanley and Hoberg (2010)     | IPO Prospectus          | single-label classifier                        |\n",
    "| Li (2010)                    | 10-K MD&A               | single-label classifier                        |\n",
    "| Huang and Li (2011)          | 10-K Risk Factors       | multi-label classifier                         |\n",
    "\n",
    "\n",
    "In Li (2008), the author  examines the relationship between corporate earnings and 10-K filing readability.\n",
    "To measure readability the author uses the two basic metrics:\n",
    "\n",
    "* The Fog Index: based on average sentence length and the number of complex words with 3 or more syllables. \n",
    "$$\n",
    "0.4 \\times ( \\frac{words}{sentences} + 100 \\times \\frac{complex_words}{words} )\n",
    "$$\n",
    "\n",
    "* Length: the total length of the 10-K filing\n",
    "\n",
    "Li (2008) found that companies with 10-K filings that were longer and less readable (higher Fog index), had lower earnings and generally were in poorer financial conditions. \n",
    "\n",
    "Tetlock et al. (2008) examine if sentiment on the Wall Street Journal had any impact on the stock market. \n",
    "Sentiment is obtained  by the number of positive words and negative words categorized by the General Inquirer (GI), a popular dictionary used by psychologists. Tetlock et al. (2008) find that media pessimism causes downward pressure on market prices. \n",
    "  \n",
    "\n",
    "Feldman et al. (2009) were first to focus specifically on the management's discussion and analysis (MD&A) section. This is because the MD&A offers the most subjectivity in 10-K filings, and thus is best placed for sentiment analysis.\n",
    "Their analysis remained relatively simplistic, and focused on tone change via word categorization.\n",
    "Their results suggested that stock market reactions around SEC filings were positively related to tone change in the MD&A section. \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial Part 1: Getting MD&A Textual Data\n",
    "\n",
    "In this section, we will run through how to download 10-K / 10-Q reports from the EDGAR database managed by the SEC.\n",
    "This is only for US listed stocks. \n",
    "\n",
    "\n",
    "First, we need to download the master index file from EDGAR.\n",
    "For simplicity without a loss of generality, let us simply look at the year 2018, quarter 1.\n",
    "Therefore, we will be downloading links to company 10-Q reports in this particular case.\n",
    "This will be saved in a file named `master.idx'.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import urllib.request\n",
    "import urllib.error\n",
    "\n",
    "idx_url = 'https://www.sec.gov/Archives/edgar/full-index/2018/QTR1/master.idx'\n",
    "response = urllib.request.urlopen(idx_url)\n",
    "out_file = open('master.idx', 'wb')\n",
    "shutil.copyfileobj(response, out_file)\n",
    "out_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open up the master file and have a peek inside, you will realise that there a lot of different types of forms.\n",
    "We're only interested in 10-Q files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"master.idx\") as file_in:\n",
    "    head = [next(file_in) for x in range(15)]\n",
    "     \n",
    "print(head[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we have the filing url to Nicholas Financial Inc's 10-Q report.\n",
    "Now, we can proceed to download the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'urllib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-a1474f88a9df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfiling_url\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"edgar/data/1000045/0001193125-18-037381.txt\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0murllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'http://www.sec.gov/Archives/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfiling_url\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mraw_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'urllib' is not defined"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "filing_url = \"edgar/data/1000045/0001193125-18-037381.txt\"\n",
    "file = urllib.request.urlopen('http://www.sec.gov/Archives/' + filing_url)\n",
    "raw_text = file.read()\n",
    "soup = BeautifulSoup(raw_text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you would like to view the 10-Q file in HTML format, you can use the prettify method and write to your local drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = soup.prettify(\"utf-8\")\n",
    "with open(\"output_10Q.html\", \"wb\") as file:\n",
    "    file.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can proceed to clean the text, removing html tags, non-ascii characters and other formating quirks using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clean = re.sub(r'[^\\x00-\\x7F]+|\\W{2,}', ' ', soup.document.get_text())\n",
    "text_clean = re.sub('\\n', ' ', text_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In theory, with `text_clean`, we are now able to run sentiment analysis. \n",
    "However, if we want to isolate the management discussion and analysis section, we need to do some more work.\n",
    "\n",
    "First, we need to identify when `management's discussion and analysis` is first brought up in the corpus. \n",
    "Any text before this point can be trimmed, as it is no longer necessary.\n",
    "We can use the re.search() function for this. (re.I is short for re.IGNORECASE and re.M is short for re.MULTILINE)\n",
    "\n",
    "However, the first identification of MDA is usually in the content's page. Therefore, it is the second time we find the term `management's discussion and analysis` that the actual section begins.\n",
    "\n",
    "In a standard 10-Q report, the management discussion and analysis section occurs just directly before the \n",
    "`Quantitative and Qualitative Disclosures about Market Risk` section. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trim all the text before the management's discussion and analysis section\n",
    "trim_beginning = re.search(r'management[\\s\\']*s discussion and analysis', text_clean, re.M | re.I)\n",
    "text_tmp = text_clean[trim_beginning.end():]\n",
    "trim_beginning = re.search(r'management[\\s\\']*s discussion and analysis', text_tmp, re.M | re.I)\n",
    "text_tmp = text_tmp[trim_beginning.start():]\n",
    "\n",
    "# Trim all the text after the management's discussion and analysis section\n",
    "trim_end = re.search(r'quantitative and qualitative', text_tmp, re.M | re.I)\n",
    "text_mda = text_tmp[:trim_end.start()]\n",
    "\n",
    "# Resulting management's discussion and analysis section after trim\n",
    "print(text_mda[0:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tutorial Part 2: Conducting Sentiment Analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "Huang, K.-W. and Z. Li. 2011. \"A Multilabel Text Classification Algorithm for Labeling Risk Factors in SEC Form 10-K,\" ACM Transactions on MIS (2:3), Article 18. \n",
    "\n",
    "Humpherys, S. L., K. C. Moffitt, et al. 2011. \"Identification of fraudulent financial statements using linguistic credibility analysis,\" Decision Support Systems (50:3), pp.  585–594.\n",
    "\n",
    "Kravet, T. and V. Muslu (2013). \"Textual Risk Disclosures and Investors' Risk Perceptions,\" Review of Accounting Studies.\n",
    "\n",
    "Li, F. 2010. \"The Information Content of Forward-Looking Statements in Corporate Filings—A Naive Bayesian Machine Learning Approach,\" Journal of Accounting Research (48:5), pp.  1049-1102. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
